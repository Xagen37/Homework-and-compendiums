{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508afda8-43f4-4236-97d4-9cf9d8ab022c",
   "metadata": {},
   "source": [
    "# Натянуть сову на линейное пространство\n",
    "\n",
    "Создайте эмбеддинги слов и визуализируйте векторные операции над ними: сложение, вычитание, взятие ближайшего, дальнейшего и прочее. Сравните качество представлений gensim и BERT с точки зрения операций над словами, докажите примерами.\n",
    "\n",
    "Для создания эмбеддингов с gensim обучите модель на нормализованных текстовых данных. Данные найдите на kaggle или выберите один из предложенных датасетов. Для создания эмбеддингов с BERT используйте предобученные модели.\n",
    "\n",
    "Предлагаемые датасеты:\n",
    " - [sentiment твитов про ковид](https://www.kaggle.com/datatattle/covid-19-nlp-text-classification)\n",
    " - [Amazon product reviews](https://www.kaggle.com/kashnitsky/hierarchical-text-classification)\n",
    " - [Отзывы интернет-магазина](https://www.kaggle.com/shymammoth/shopee-reviews)\n",
    " - [Тексты статей конференции NIPS](https://www.kaggle.com/rowhitswami/nips-papers-1987-2019-updated?select=papers.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ceb505-d96d-44eb-8eb7-8f6cb421f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff9912-5a01-4d9d-b614-a952ef103544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/corona.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab08057-1100-4b8e-958c-69e2306d73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_data = data.OriginalTweet.to_frame()\n",
    "\n",
    "txt_data.info()\n",
    "txt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be35fec-04ad-4e5d-9b74-caeb41dd20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "nltk.data.path.append('./data')\n",
    "nltk.download('stopwords', download_dir = './data')\n",
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b82e73-d25b-4af0-aaa4-65ff452170e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import *\n",
    "\n",
    "def build_vocab(texts: List[List[str]]) -> Counter:\n",
    "    words = list(chain.from_iterable(texts))\n",
    "    vocab = Counter(words)\n",
    "    return vocab\n",
    "\n",
    "custom_filters = [lambda x: x.lower(),\n",
    "                  lambda x: re.sub(r'http\\S+', '', x),\n",
    "                  strip_tags,\n",
    "                  strip_non_alphanum,\n",
    "                  strip_punctuation,\n",
    "                  strip_multiple_whitespaces,\n",
    "                  strip_numeric,\n",
    "                  lambda x: remove_stopwords(x, stopwords = eng_stopwords),\n",
    "                  \n",
    "                  stem_text]\n",
    "\n",
    "def preprocess(text: str) -> np.ndarray:\n",
    "    return preprocess_string(text, filters = custom_filters)\n",
    "\n",
    "texts = txt_data.OriginalTweet.apply(preprocess)\n",
    "vocab = build_vocab(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abb60a-96ac-416f-8495-6f071abbbca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab))\n",
    "print(vocab.most_common(10))\n",
    "\n",
    "print(len(texts))\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2040f1b-8cb6-4c2b-b541-676fb78ce87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# gs = Word2Vec(sentences = texts,\n",
    "#               vector_size = 256,\n",
    "#               seed = 0,\n",
    "#               min_count = 1,\n",
    "#               workers = 8,\n",
    "#               sg = False,\n",
    "#               epochs = 10\n",
    "#              )\n",
    "\n",
    "gs = Word2Vec.load(\"data/models/gs_mod.model\")\n",
    "\n",
    "print(gs.wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af223e-f724-44aa-b5b3-855f89d38c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "points = umap.UMAP(random_state = 0, n_jobs = 8).fit_transform(gs.wv.vectors[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05fbaf-0740-4801-86f2-5e3b1b689949",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "ax.scatter(points[:, 0], points[:, 1])\n",
    "\n",
    "for i, txt in enumerate(gs.wv.index_to_key[:500]):\n",
    "    ax.annotate(txt, (points[i, 0], points[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db5e6a-a2dc-400b-a45f-8d1fe8d7e2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # возращать эмбеддинги каждого слова\n",
    "                                  )\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "bert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78937c-7786-4125-9926-35c08c8ad376",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def make_sentence_embedding_bert(text: str) -> torch.Tensor:\n",
    "    tokens_tensor, _, segments_tensors = tokenizer(text, return_tensors = 'pt').values()\n",
    "    \n",
    "    # calc embeddings\n",
    "    outputs = bert(tokens_tensor, segments_tensors)\n",
    "    last_layer_embs = outputs.last_hidden_state\n",
    "    sentense_embedding = last_layer_embs.squeeze(0).sum(dim=0)\n",
    "    \n",
    "    return sentense_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8f087-d90d-48d7-b02f-4ca49b8eca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts.astype(str)\n",
    "embs_bert = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db93a59-3eb6-4aa3-93b7-102acedeee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text in tqdm(vocab):\n",
    "#     emb = make_sentence_embedding_bert(text)\n",
    "#     embs_bert.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8faad-2e5e-40b5-8d8c-b9c555eceac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_save = np.stack([ten.detach().numpy() for ten in embs_bert])\n",
    "# np.save(\"data/models/bert2\", to_save)\n",
    "# gs.save(\"data/models/gs_mod.model\")\n",
    "embs_bert = np.load(\"data/models/bert2.npy\")\n",
    "# gs = Word2Vec.load(\"data/models/gs_mod.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a8908-5f92-4836-9220-f7189bbb17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"data/models/vocab2\", list(vocab.keys()))\n",
    "# fixed_vocab = list(vocab.keys())\n",
    "fixed_vocab = np.load(\"data/models/vocab2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fff78f-4793-4022-bca2-6ca1bd583222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.wv.vectors.shape)\n",
    "print(embs_bert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e6381-753c-4a11-b562-d011c99479c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_bert = torch.from_numpy(embs_bert)\n",
    "ten_gs = torch.from_numpy(gs.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde61c1-4a31-4e74-8929-e49ceec8bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ten_bert.size())\n",
    "print(ten_gs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2d431-3072-484e-adac-002efcfa13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_sum(query: str) -> List[float]:\n",
    "    return sum([make_sentence_embedding_bert(word) for word in query.split()])\n",
    "\n",
    "def best_gs(query: str) -> List[Tuple[str, float]]:\n",
    "    try:\n",
    "        return gs.wv.most_similar(positive = preprocess(query))\n",
    "    except KeyError:\n",
    "        return [(\"None\", 0)] * 10\n",
    "\n",
    "def best_bert(query: str) -> List[Tuple[str, float]]:\n",
    "    q_emb = make_sentence_embedding_bert(query)\n",
    "    similarities = torch.nn.functional.cosine_similarity(q_emb, ten_bert, dim = -1)\n",
    "    temp = list(zip(fixed_vocab, similarities.detach().numpy()))\n",
    "    temp.sort(key = lambda tup: tup[1], reverse = True)\n",
    "    return temp[:10]\n",
    "\n",
    "def best_bert_sum(query: str) -> pd.DataFrame:\n",
    "    q_emb = bert_sum(query)\n",
    "    similarities = torch.nn.functional.cosine_similarity(q_emb, ten_bert, dim = -1)\n",
    "    temp = list(zip(fixed_vocab, similarities.detach().numpy()))\n",
    "    temp.sort(key = lambda tup: tup[1], reverse = True)\n",
    "    return pd.DataFrame(temp[:10], columns = ['bert_word', 'bert_sim'])\n",
    "\n",
    "def bests(query: str) -> pd.DataFrame:\n",
    "    gsdf = pd.DataFrame(best_gs(query), columns = ['gs_word', 'gs_sim'])\n",
    "    bertdf = pd.DataFrame(best_bert(query), columns = ['bert_word', 'bert_sim'])\n",
    "    return pd.concat([gsdf, bertdf], axis = 1)\n",
    "\n",
    "def worst_gs(query: str) -> List[Tuple[str, float]]:\n",
    "    try:\n",
    "        return gs.wv.most_similar(negative = preprocess(query))\n",
    "    except KeyError:\n",
    "        return [(\"None\", 0)] * 10\n",
    "\n",
    "def worst_bert(query: str) -> List[Tuple[str, float]]:\n",
    "    q_emb = make_sentence_embedding_bert(query)\n",
    "    similarities = torch.nn.functional.cosine_similarity(q_emb, ten_bert, dim = -1)\n",
    "    temp = list(zip(fixed_vocab, similarities.detach().numpy()))\n",
    "    temp.sort(key = lambda tup: tup[1])\n",
    "    return temp[:10]\n",
    "\n",
    "def worsts(query: str) -> pd.DataFrame:\n",
    "    gsdf = pd.DataFrame(worst_gs(query), columns = ['gs_word', 'gs_sim'])\n",
    "    bertdf = pd.DataFrame(worst_bert(query), columns = ['bert_word', 'bert_sim'])\n",
    "    return pd.concat([gsdf, bertdf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115b280-0c70-49cc-96ca-56563b7934a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "print('covid: ')\n",
    "display(bests('covid'))\n",
    "print('death: ')\n",
    "display(bests('death'))\n",
    "print('cure: ')\n",
    "display(bests('cure'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899400e0-400d-422a-8463-5ce466def57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"schizophrenia: \")\n",
    "display(bests('schizophrenia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36367703-6ff3-4c1b-8522-6a1589c53b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"covid vaccine\"\n",
    "q2 = \"vaccine covid\"\n",
    "display(bests(q1))\n",
    "display(bests(q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb520b6-c57f-4724-8d26-3687528d4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(best_bert_sum(q1))\n",
    "display(best_bert_sum(q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066c43f-599f-497a-9166-5d288805f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs = gs.wv.get_vector('covid')\n",
    "dgs = gs.wv.get_vector('death')\n",
    "display(pd.DataFrame(gs.wv.similar_by_vector(cgs - dgs), columns = ['gs_word', 'gs_sim']))\n",
    "display(pd.DataFrame(gs.wv.similar_by_vector(dgs - cgs), columns = ['gs_word', 'gs_sim']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61719dda-33c1-45fc-9d74-f7d019163aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbert = make_sentence_embedding_bert('covid')\n",
    "dbert = make_sentence_embedding_bert('death')\n",
    "\n",
    "similarities = torch.nn.functional.cosine_similarity(cbert - dbert, ten_bert, dim = -1)\n",
    "temp = list(zip(fixed_vocab, similarities.detach().numpy()))\n",
    "temp.sort(key = lambda tup: tup[1])\n",
    "v1 = temp[:10]\n",
    "\n",
    "similarities = torch.nn.functional.cosine_similarity(dbert - cbert, ten_bert, dim = -1)\n",
    "temp = list(zip(fixed_vocab, similarities.detach().numpy()))\n",
    "temp.sort(key = lambda tup: tup[1])\n",
    "v2 = temp[:10]\n",
    "\n",
    "display(pd.DataFrame(v1, columns = ['bert_word', 'bert_sim']))\n",
    "display(pd.DataFrame(v2, columns = ['bert_word', 'bert_sim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104eb6c1-8b46-4dd3-b16c-b206bb73481f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd320b53-419a-48e8-a135-20a78849598a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b49375-7002-4d2a-a54f-688641ad45c8",
   "metadata": {},
   "source": [
    "# Projector\n",
    "\n",
    "Из прошлого задания вы выяснили наиболее хорошую для представления связей между словами модель. Спроецируйте ~2-3 тысячи наиболее популярных слов из выбранного корпуса в tensorflow projector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1f2f3-dd25-4d37-883d-b2bbfecfb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2033518-79a7-4c8e-abf6-8167f6551975",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = np.stack(embs_bert[:2000])\n",
    "writer.add_embedding(embs,\n",
    "                     metadata = fixed_vocab[:2000])\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
